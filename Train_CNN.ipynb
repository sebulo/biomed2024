{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f622dfbf-e137-4655-9f6d-2d638a4ea846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src import utils, cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8aead-18cc-4549-9962-b23ecde623e9",
   "metadata": {},
   "source": [
    "### Define some parameters\n",
    "Importantly, set classification to true for cultivar classification or false for regression towards yield, stomatal conductance, chlorophyll flourescence and fertilizer amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b0727b-7154-44f8-963f-0b113581656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "\n",
    "epochs = 5000\n",
    "lr = 0.00001\n",
    "\n",
    "batch_size = 16\n",
    "num_accumulated_batches = 1 # Number of gradient accumulation steps\n",
    "# Effective batch size = batch_size * num_accumulated_batches\n",
    "\n",
    "# wandb project name\n",
    "project_name = f'outlier_challenge'\n",
    "\n",
    "# Model checkpointing settings\n",
    "model_path = f'models/'\n",
    "model_name = f'resnet50'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11f446-639e-40d6-9ce1-34edc5188061",
   "metadata": {},
   "source": [
    "### Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bdf2195-87df-4d39-9ca8-21887df386c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataloaders\n",
    "train_loader, val_loader = utils.get_data_loaders(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbec7fb-dda6-4a00-9508-39662c1f36e5",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d621110e-0830-4707-9b29-26518a18db7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwillap\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240815_095026-outlier_challenge_resnet50</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/willap/outlier_challenge/runs/outlier_challenge_resnet50' target=\"_blank\">resnet50</a></strong> to <a href='https://wandb.ai/willap/outlier_challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/willap/outlier_challenge' target=\"_blank\">https://wandb.ai/willap/outlier_challenge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/willap/outlier_challenge/runs/outlier_challenge_resnet50' target=\"_blank\">https://wandb.ai/willap/outlier_challenge/runs/outlier_challenge_resnet50</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Billy\\miniconda3\\envs\\matrix\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:639: Checkpoint directory C:\\Users\\Billy\\Downloads\\challenge_data\\challenge_data\\models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | net    | Sequential | 25.6 M\n",
      "1 | linear | Linear     | 1.0 K \n",
      "--------------------------------------\n",
      "25.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 M    Total params\n",
      "102.232   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499163400adb4df7a48f40654e1677f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up WandB logger\n",
    "if resume:\n",
    "    logger = WandbLogger(name=model_name, project=project_name, id=f'{project_name}_{model_name}', log_model=False, resume='must')\n",
    "else:\n",
    "    logger = WandbLogger(name=model_name, project=project_name, id=f'{project_name}_{model_name}', log_model=False)\n",
    "    \n",
    "\n",
    "# Set up callbacks\n",
    "best_checkpoint_callback = ModelCheckpoint(dirpath=model_path,\n",
    "                                           filename=f'{model_name}_best',\n",
    "                                           monitor='val/loss',\n",
    "                                           enable_version_counter=False)\n",
    "\n",
    "last_checkpoint_callback = ModelCheckpoint(dirpath=model_path,\n",
    "                                           filename=f'{model_name}',\n",
    "                                           monitor=None,\n",
    "                                           enable_version_counter=False)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val/loss',\n",
    "                                        min_delta=0.00,\n",
    "                                        patience=20,\n",
    "                                        verbose=True,\n",
    "                                        mode='min')\n",
    "\n",
    "callbacks = [best_checkpoint_callback, last_checkpoint_callback, early_stopping_callback]\n",
    "\n",
    "# Create model\n",
    "model = cnn.CNN(lr=lr)\n",
    "\n",
    "# Set up trainer\n",
    "trainer = L.Trainer(max_epochs=epochs,\n",
    "                    precision='16-mixed',\n",
    "                    log_every_n_steps=1,\n",
    "                    logger=logger,\n",
    "                    callbacks=callbacks,\n",
    "                    accelerator=\"gpu\",\n",
    "                    accumulate_grad_batches=num_accumulated_batches)\n",
    "\n",
    "# Train model\n",
    "if resume:\n",
    "    trainer.fit(model, train_loader, val_loader, ckpt_path=f'{model_path}/{model_name}.ckpt')\n",
    "else:\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb247d2b-c36e-415f-95d9-6b4ff57395a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21bf5433-584e-4b2c-b587-e18c27008ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Billy\\miniconda3\\envs\\matrix\\Lib\\site-packages\\numpy\\core\\_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2184\n",
      "200 2184\n",
      "300 2184\n",
      "400 2184\n",
      "500 2184\n",
      "600 2184\n",
      "700 2184\n",
      "800 2184\n",
      "900 2184\n",
      "1000 2184\n",
      "1100 2184\n",
      "1200 2184\n",
      "1300 2184\n",
      "1400 2184\n",
      "1500 2184\n",
      "1600 2184\n",
      "1700 2184\n",
      "1800 2184\n",
      "1900 2184\n",
      "2000 2184\n",
      "2100 2184\n",
      "0 547\n",
      "100 547\n",
      "200 547\n",
      "300 547\n",
      "400 547\n",
      "500 547\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import v2\n",
    "from torchvision import tv_tensors\n",
    "import torch\n",
    "\n",
    "def load_25D(file):\n",
    "    \n",
    "    image = utils.read_file(file)\n",
    "\n",
    "    img0 = np.std(image[100:140], axis=0)\n",
    "    img1 = np.std(image[:,100:140], axis=1)\n",
    "    img2 = np.std(image[:,:,100:140], axis=2)\n",
    "    \n",
    "    image = np.stack([img0, img1, img2], axis=-1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def process_data(df):\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        image = load_25D(df.image_file.iloc[i])\n",
    "        mask = load_25D(df.mask_file.iloc[i])\n",
    "        dist = load_25D(df.dist_file.iloc[i])\n",
    "        \n",
    "        image = np.concatenate([image,mask,dist], axis=-1)\n",
    "        \n",
    "        data.append(image)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(i, len(df))\n",
    "        \n",
    "    return np.array(data)\n",
    "    \n",
    "train_data = process_data(pd.read_csv('train_data.csv'))\n",
    "test_data = process_data(pd.read_csv('test_data.csv'))\n",
    "\n",
    "np.save('train_data.npy', train_data)\n",
    "np.save('test_data.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83993ecd-d867-4f7e-b191-9ad0368b6bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_file, mask_file, dist_file):\n",
    "    \n",
    "    transforms = v2.Compose([utils.Standardize(),\n",
    "                                  v2.Resize(size=(224,224))])\n",
    "\n",
    "    \n",
    "    image = load_25D(image_file)\n",
    "    mask = load_25D(mask_file)\n",
    "    dist = load_25D(dist_file)\n",
    "\n",
    "    image = np.concatenate([image,mask,dist], axis=-1)\n",
    "\n",
    "    image = np.moveaxis(image, -1, 0)\n",
    "\n",
    "    # Convert to tv_tensors\n",
    "    image = tv_tensors.Image(torch.tensor(image)\n",
    "\n",
    "    # Apply transforms\n",
    "    image = transforms(image)\n",
    "    \n",
    "    return image.to(torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb541d4-c9fb-4a8e-91a7-02b1e8b675ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vtk\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "test_files = np.sort(glob.glob('test/crops/*label*'))\n",
    "\n",
    "def create_detection(model, X_test, test_files, only_200=True):\n",
    "    \n",
    "    test_files_200 = np.genfromtxt('test_files_200.txt', str)\n",
    "\n",
    "    model.cuda()\n",
    "\n",
    "    num_outlier = 0\n",
    "\n",
    "    # Create results\n",
    "    test_results = []\n",
    "    for i in range(len(test_files)):\n",
    "        \n",
    "        scan_id = test_files[i].split('\\\\')[-1].split('_')[0] + '_' + test_files[i].split('\\\\')[-1].split('_')[1]\n",
    "\n",
    "        if only_200:\n",
    "            if scan_id in test_files_200:\n",
    "            \n",
    "                prob = torch.nn.functional.sigmoid(model(process_image(X_test[i])[None,...]))\n",
    "                prob = prob.detach().cpu().numpy().ravel()[0]\n",
    "                pred = int(prob > 0.5)\n",
    "\n",
    "                if pred == 1:\n",
    "                    num_outlier += 1\n",
    "        \n",
    "                # Remember to cast bools to int for json serialization\n",
    "                test_results.append({\"scan_id\": scan_id, \"outlier\": pred})\n",
    "        else:\n",
    "            \n",
    "            prob = torch.nn.functional.sigmoid(model(process_image(X_test[i])[None,...]))\n",
    "            prob = prob.detach().cpu().numpy().ravel()[0]\n",
    "    \n",
    "            # Remember to cast bools to int for json serialization\n",
    "            test_results.append({\"scan_id\": scan_id, \"outlier\": int(prob > 0.5)})\n",
    "\n",
    "    print(num_outlier / 200)\n",
    "    # Write results to JSON file\n",
    "    if only_200:\n",
    "        with open(\"test_results_200.json\", 'w') as json_file:\n",
    "            json.dump(test_results, json_file, indent=4)\n",
    "    else:\n",
    "        with open(\"test_results.json\", 'w') as json_file:\n",
    "            json.dump(test_results, json_file, indent=4)\n",
    "\n",
    "create_detection(model, X_test, test_files, only_200=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c740fbe-2a06-4dfe-8b18-1d974c88bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_detection(model, X_test, test_files, only_200=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
